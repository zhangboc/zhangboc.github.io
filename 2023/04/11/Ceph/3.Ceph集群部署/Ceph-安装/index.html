<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Ceph-安装 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="article">
<meta property="og:title" content="Ceph-安装">
<meta property="og:url" content="https://github.com/zhangboc/zhangboc.github.io.git/2023/04/11/Ceph/3.Ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/Ceph-%E5%AE%89%E8%A3%85/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-04-10T16:00:00.000Z">
<meta property="article:modified_time" content="2023-04-11T09:54:05.262Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Ceph">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://github.com/zhangboc/zhangboc.github.io.git"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Ceph/3.Ceph集群部署/Ceph-安装" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/11/Ceph/3.Ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/Ceph-%E5%AE%89%E8%A3%85/" class="article-date">
  <time class="dt-published" datetime="2023-04-10T16:00:00.000Z" itemprop="datePublished">2023-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Ceph/">Ceph</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Ceph-安装
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1><span id></span></h1><span id="more"></span>

<!-- toc -->

<ul>
<li><a href="#%E7%8E%AF%E5%A2%83%E6%83%85%E5%86%B5">环境情况</a></li>
<li><a href="#%E4%B8%80-%E4%BF%AE%E6%94%B9hosts%E6%96%87%E4%BB%B6">一、修改HOSTS文件</a></li>
<li><a href="#%E4%BA%8C-%E9%85%8D%E7%BD%AE%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95">二、配置无密码登录</a></li>
<li><a href="#%E4%B8%89-%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE">三、安全设置</a><ul>
<li><a href="#%E4%B8%80-%E5%85%B3%E9%97%ADselinux">一、关闭Selinux</a></li>
<li><a href="#%E4%BA%8C-%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99">二、关闭防火墙</a></li>
</ul>
</li>
<li><a href="#%E5%9B%9B-ntp%E8%AE%BE%E7%BD%AE">四、NTP设置</a></li>
<li><a href="#%E4%BA%94-%E9%85%8D%E7%BD%AEyum%E6%BA%90">五、配置Yum源</a></li>
<li><a href="#%E5%85%AD-%E5%AE%89%E8%A3%85ceph-deploy">六、安装Ceph-deploy</a></li>
<li><a href="#%E4%B8%83-%E5%AE%89%E8%A3%85mon%E8%8A%82%E7%82%B9">七、安装Mon节点</a><ul>
<li><a href="#%E4%B8%80-%E9%87%8D%E7%BD%AE%E9%9B%86%E7%BE%A4">一、重置集群</a></li>
<li><a href="#%E4%BA%8C-%E5%AE%89%E8%A3%85%E7%9B%B8%E5%85%B3%E8%BD%AF%E4%BB%B6">二、安装相关软件</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89-mon-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E5%AE%89%E8%A3%85mgr">三、Mon 初始化及安装MGR</a></li>
<li><a href="#%E5%85%AB-%E9%83%A8%E7%BD%B2osd%E8%8A%82%E7%82%B9">八、部署OSD节点</a></li>
<li><a href="#%E4%B9%9D-%E6%89%A9%E5%B1%95mon%E5%92%8Cmgr">九、扩展MON和MGR</a><ul>
<li><a href="#%E4%B8%80-mon">一、Mon</a></li>
<li><a href="#%E4%BA%8C-mgr">二、MGR</a></li>
</ul>
</li>
<li><a href="#%E5%8D%81-%E5%88%9B%E5%BB%BA%E8%B5%84%E6%BA%90%E6%B1%A0pool">十、创建资源池Pool</a></li>
</ul>
<!-- tocstop -->

<h1><span id="环境情况">环境情况</span></h1><table>
    <tr>
        <td>操作系统</td>
        <td>公共网络</td>
        <td>集群网络</td>
        <td>节点名称</td>
    </tr>
    <tr>
        <td rowspan="4">Centos 7.9</td>
    </tr>
        <tr>
            <td>192.168.187.201</td>
            <td>192.168.199.201</td>
            <td>node-1</td>
        </tr>
        <tr>
            <td>192.168.187.202</td>
            <td>192.168.199.202</td>
            <td>node-2</td>
        </tr>
        <tr>
            <td>192.168.187.203</td>
            <td>192.168.199.203</td>
            <td>node-2</td>
        </tr>
</table>

<h1><span id="一-修改hosts文件">一、修改HOSTS文件</span></h1><p><strong>所有主机均要修改</strong></p>
<pre><code>[root@node-1 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.199.201 node-1
192.168.199.202 node-2
192.168.199.203 node-3
</code></pre>
<h1><span id="二-配置无密码登录">二、配置无密码登录</span></h1><p><strong>Node-1：</strong></p>
<pre><code>[root@node-1 ~]# ssh-keygen 
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): 
Created directory &#39;/root/.ssh&#39;.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:RNd/EfeRh3t7C73PD//lsUVTQpf84hKM5Dy3CdWj6iQ root@node-1
The keys randomart image is:
+---[RSA 2048]----+
|        . .. .o+*|
|       . .. o.+*=|
|        .+ + o.o*|
|       .  * = +.=|
|        S  = =.=o|
|        E o +..+o|
|         +   .o.*|
|          .    B=|
|               .@|
+----[SHA256]-----+
[root@node-1 ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub node-2
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;
The authenticity of host &#39;node-2 (192.168.199.202)&#39; can t be established.
ECDSA key fingerprint is SHA256:ELWxoLpZlehIUk5OpR5CO/OmzpHyNco8PkV4ztDCV7w.
ECDSA key fingerprint is MD5:62:87:b6:99:64:b1:b2:d3:40:f1:d5:e8:d3:a1:8a:18.
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@node-2 s password: 

Number of key(s) added: 1

Now try logging into the machine, with:   &quot;ssh &#39;node-2&#39;&quot;
and check to make sure that only the key(s) you wanted were added.

[root@node-1 ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub node-3
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;
The authenticity of host &#39;node-3 (192.168.199.203)&#39; can t be established.
ECDSA key fingerprint is SHA256:ELWxoLpZlehIUk5OpR5CO/OmzpHyNco8PkV4ztDCV7w.
ECDSA key fingerprint is MD5:62:87:b6:99:64:b1:b2:d3:40:f1:d5:e8:d3:a1:8a:18.
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@node-3 s password: 

Number of key(s) added: 1

Now try logging into the machine, with:   &quot;ssh &#39;node-3&#39;&quot;
and check to make sure that only the key(s) you wanted were added.
</code></pre>
<h1><span id="三-安全设置">三、安全设置</span></h1><h2><span id="一-关闭selinux">一、关闭Selinux</span></h2><p><strong>所有节点执行，将enforcing修改成disabled：</strong></p>
<pre><code>[root@node-1 ~]# cat /etc/selinux/config 

# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=disabled
# SELINUXTYPE= can take one of three values:
#     targeted - Targeted processes are protected,
#     minimum - Modification of targeted policy. Only selected processes are protected. 
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted
[root@node-1 ~]# setenforce 0 #临时关闭
[root@node-1 ~]# getenforce #查看状态
Disabled
</code></pre>
<h2><span id="二-关闭防火墙">二、关闭防火墙</span></h2><p><strong>所有节点均执行：</strong></p>
<pre><code>[root@node-1 ~]# firewall-cmd --list-all #查看防火墙状态
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens33 ens36
  sources: 
  services: dhcpv6-client ssh
  ports: 
  protocols: 
  masquerade: no
  forward-ports: 
  source-ports: 
  icmp-blocks: 
  rich rules: 
[root@node-1 ~]# systemctl disable firewalld #禁止开机自启
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
[root@node-1 ~]# systemctl stop firewalld #关闭防火墙
[root@node-3 ~]# firewall-cmd --list-all #查看状态
FirewallD is not running
</code></pre>
<h1><span id="四-ntp设置">四、NTP设置</span></h1><p><strong>所有节点执行：</strong></p>
<pre><code>[root@node-3 ~]# cd /etc/yum.repos.d/
[root@node-3 yum.repos.d]# ls
CentOS-Base.repo  CentOS-Debuginfo.repo  CentOS-Media.repo    CentOS-Vault.repo
CentOS-CR.repo    CentOS-fasttrack.repo  CentOS-Sources.repo  CentOS-x86_64-kernel.repo
[root@node-3 yum.repos.d]# rm -rf *
[root@node-3 yum.repos.d]# ls
[root@node-1 yum.repos.d]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  2523  100  2523    0     0   6577      0 --:--:-- --:--:-- --:--:--  6587
[root@node-1 yum.repos.d]# 
[root@node-1 yum.repos.d]# ls
CentOS-Base.repo
[root@node-1 yum.repos.d]# yum clean all &amp;&amp; yum makecache #清除缓存
[root@node-1 yum.repos.d]# yum install ntp -y #安装NTP
[root@node-1 yum.repos.d]# systemctl restart ntpd #启动NTP服务
[root@node-1 yum.repos.d]# systemctl enable ntpd #设置开机自启动
Created symlink from /etc/systemd/system/multi-user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.
[root@node-1 yum.repos.d]# ntpq -pn #查看NTP状态
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
+78.46.102.180   176.9.157.12     3 u   33   64    1  245.918   17.006  14.216
*144.76.76.107   192.53.103.103   2 u   33   64    1  214.840    0.073   0.324
 193.182.111.14  192.36.143.153   2 u   67   64    1  293.490   -4.158   1.037
 [root@node-2 ~]# crontab -l #使用crontab -e 编辑，每分钟同步一次时间
*/1 * * * * /usr/sbin/ntpdate node-1;/sbin/hwclock -w
</code></pre>
<p><strong>node-2、node-3执行：</strong></p>
<pre><code>[root@node-3 yum.repos.d]# cat /etc/ntp.conf 
# For more information about this file, see the man pages
# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).

driftfile /var/lib/ntp/drift

# Permit time synchronization with our time source, but do not
# permit the source to query or modify the service on this system.
restrict default nomodify notrap nopeer noquery

# Permit all access over the loopback interface.  This could
# be tightened as well, but to do so would effect some of
# the administrative functions.
restrict 127.0.0.1 
restrict ::1

# Hosts on local network are less restricted.
#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap

# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (http://www.pool.ntp.org/join.html).
server node-1 iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst

#broadcast 192.168.1.255 autokey    # broadcast server
#broadcastclient            # broadcast client
#broadcast 224.0.1.1 autokey        # multicast server
#multicastclient 224.0.1.1        # multicast client
#manycastserver 239.255.254.254        # manycast server
#manycastclient 239.255.254.254 autokey # manycast client

# Enable public key cryptography.
#crypto

includefile /etc/ntp/crypto/pw

# Key file containing the keys and key identifiers used when operating
# with symmetric key cryptography. 
keys /etc/ntp/keys

# Specify the key identifiers which are trusted.
#trustedkey 4 8 42

# Specify the key identifier to use with the ntpdc utility.
#requestkey 8

# Specify the key identifier to use with the ntpq utility.
#controlkey 8

# Enable writing of statistics records.
#statistics clockstats cryptostats loopstats peerstats

# Disable the monitoring facility to prevent amplification attacks using ntpdc
# monlist command when default restrict does not include the noquery flag. See
# CVE-2013-5211 for more details.
# Note: Monitoring will not be disabled with the limited restriction flag.
disable monitor
</code></pre>
<h1><span id="五-配置yum源">五、配置Yum源</span></h1><p><strong>所有节点执行：</strong></p>
<pre><code>[root@node-3 ~]# cd /etc/yum.repos.d/
[root@node-3 yum.repos.d]# ls
CentOS-Base.repo  CentOS-Debuginfo.repo  CentOS-Media.repo    CentOS-Vault.repo
CentOS-CR.repo    CentOS-fasttrack.repo  CentOS-Sources.repo  CentOS-x86_64-kernel.repo
[root@node-3 yum.repos.d]# rm -rf *
[root@node-3 yum.repos.d]# ls
[root@node-1 yum.repos.d]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  2523  100  2523    0     0   6577      0 --:--:-- --:--:-- --:--:--  6587
[root@node-1 yum.repos.d]# 
[root@node-1 yum.repos.d]# ls
CentOS-Base.repo
[root@node-1 yum.repos.d]# curl -o /etc/yum.repos.d/epel.repo https://mirrors.aliyun.com/repo/epel-7.repo
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100   664  100   664    0     0   2193      0 --:--:-- --:--:-- --:--:--  2191
[root@node-1 yum.repos.d]# 
[root@node-1 yum.repos.d]# ls
CentOS-Base.repo  epel.repo
[root@node-1 yum.repos.d]# cat ceph.repo  #手动创建ceph.repo文件内容如下
[norch]
name=norch
baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/
enabled=1
gpgcheck=0

[x86_64]
name=x86 64
baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/
enabled=1
gpgcheck=0
[root@node-1 yum.repos.d]# yum clean all &amp;&amp; yum makecache #清除缓存
[root@node-1 yum.repos.d]# yum update -y
</code></pre>
<h1><span id="六-安装ceph-deploy">六、安装Ceph-deploy</span></h1><p><strong>Node1执行</strong></p>
<pre><code>[root@node-1 yum.repos.d]# yum install python-setuptools ceph-deploy -y #安装核心软件
[root@node-1 yum.repos.d]# ceph-deploy --version #查看版本
2.0.1
</code></pre>
<h1><span id="七-安装mon节点">七、安装Mon节点</span></h1><h2><span id="一-重置集群">一、重置集群</span></h2><p><strong>如果安装失败或者重新安装时执行：</strong></p>
<pre><code>ceph-deploy purge &#123;ceph-node&#125; [&#123;ceph-node&#125;]
ceph-deploy purgedata  &#123;ceph-node&#125; [&#123;ceph-node&#125;]
ceph-deploy forgetkeys
rm ceph.*
</code></pre>
<h2><span id="二-安装相关软件">二、安装相关软件</span></h2><p><strong>Node1执行：</strong></p>
<pre><code>[root@node-1 yum.repos.d]# cd /opt/
[root@node-1 opt]# mkdir my-cluster
[root@node-1 opt]# cd my-cluster/
[root@node-1 my-cluster]# ceph-deploy new --public-network 192.168.187.0/24 --cluster-network 192.168.199.0/24 node-1
</code></pre>
<p><strong>公共网络是外部访问集群时使用的，集群网络时内部同步使用的</strong><br><strong>所有节点执行：</strong></p>
<pre><code>[root@node-1 my-cluster]# yum install ceph ceph-mon ceph-mgr ceph-mds ceph-radosgw -y #安装核心软件包
</code></pre>
<h1><span id="三-mon-初始化及安装mgr">三、Mon 初始化及安装MGR</span></h1><pre><code>[root@node-1 my-cluster]# ceph-deploy mon create-initial #初始化Mon
[root@node-1 my-cluster]# ceph-deploy admin node-1 node-2 node-3 #推送最新配置到所有节点
[root@node-1 my-cluster]# ceph -s  #查看集群状态
  cluster:
    id:     e9a90625-4707-4b6b-b52f-661512ea831d
    health: HEALTH_WARN
            mon is allowing insecure global_id reclaim  #mon允许不安全的global_id回收
 
  services:
    mon: 1 daemons, quorum node-1 (age 2m)
    mgr: no daemons active
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:     
[root@node-1 my-cluster]# ceph config set mon auth_allow_insecure_global_id_reclaim false #取消mon允许不安全的global_id回收
[root@node-1 my-cluster]# ceph -s 
  cluster:
    id:     e9a90625-4707-4b6b-b52f-661512ea831d
    health: HEALTH_OK
 
  services:
    mon: 1 daemons, quorum node-1 (age 3m)
    mgr: no daemons active
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:     
 
[root@node-1 my-cluster]# ceph-deploy mgr create node-1 #安装mgr 监控服务
[root@node-1 my-cluster]#  ceph -s
  cluster:
    id:     e9a90625-4707-4b6b-b52f-661512ea831d
    health: HEALTH_WARN
            OSD count 0 &lt; osd_pool_default_size 3
 
  services:
    mon: 1 daemons, quorum node-1 (age 6m)
    mgr: node-1(active, since 55s) #查看已经成功安装
    osd: 0 osds: 0 up, 0 in
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:     
</code></pre>
<h1><span id="八-部署osd节点">八、部署OSD节点</span></h1><p><strong>node-1 执行:</strong></p>
<pre><code>[root@node-1 my-cluster]# lsblk #确定硬盘
NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda               8:0    0   20G  0 disk 
├─sda1            8:1    0    1G  0 part /boot
└─sda2            8:2    0   19G  0 part 
  ├─centos-root 253:0    0   17G  0 lvm  /
  └─centos-swap 253:1    0    2G  0 lvm  [SWAP]
sdb               8:16   0   10G  0 disk 
sdc               8:32   0   10G  0 disk 
sr0              11:0    1 1024M  0 rom 
[root@node-1 my-cluster]# ceph-deploy osd create node-1 --data /dev/sdb --journal /dev/sdb # --data指定硬盘  --journal /dev/sdb 指定加速
[root@node-1 my-cluster]# ceph-deploy osd create node-2 --data /dev/sdb --journal /dev/sdb # --data指定硬盘  --journal /dev/sdb 指定加速
[root@node-1 my-cluster]# ceph-deploy osd create node-3 --data /dev/sdb --journal /dev/sdb # --data指定硬盘  --journal /dev/sdb 指定加速
[root@node-1 my-cluster]# ceph osd tree  #查看OSD状态
ID CLASS WEIGHT  TYPE NAME       STATUS REWEIGHT PRI-AFF 
-1       0.02939 root default                            
-3       0.00980     host node-1                         
 0   hdd 0.00980         osd.0       up  1.00000 1.00000 
-5       0.00980     host node-2                         
 1   hdd 0.00980         osd.1       up  1.00000 1.00000 
-7       0.00980     host node-3                         
 2   hdd 0.00980         osd.2       up  1.00000 1.00000 
</code></pre>
<h1><span id="九-扩展mon和mgr">九、扩展MON和MGR</span></h1><p><strong>Mon 使用Paxos算法，一般都是奇数 3、5、7</strong></p>
<h2><span id="一-mon">一、Mon</span></h2><pre><code>NODE-1执行：
ceph-deploy mon add node-2 --address 192.168.187.202 #添加node-2成为Mon 并指定IP
ceph-deploy mon add node-3 --address 192.168.187.203 #添加node-3成为Mon 并指定IP
[root@node-1 my-cluster]# ceph -s  #查看Mon是否添加成功
  cluster:
    id:     e9a90625-4707-4b6b-b52f-661512ea831d
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum node-1,node-2,node-3 (age 54s) #已经添加node-2和node-3
    mgr: node-1(active, since 18m)
    osd: 3 osds: 3 up (since 8m), 3 in (since 8m)
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   3.0 GiB used, 27 GiB / 30 GiB avail
    pgs: 
[root@node-1 my-cluster]# ceph quorum_status --format json-pretty #查看Mon 仲裁情况

&#123;
    &quot;election_epoch&quot;: 12,
    &quot;quorum&quot;: [
        0,
        1,
        2
    ],
    &quot;quorum_names&quot;: [ #可以看到当前3个节点正在参加仲裁
        &quot;node-1&quot;,
        &quot;node-2&quot;,
        &quot;node-3&quot;
    ],
    &quot;quorum_leader_name&quot;: &quot;node-1&quot;, #当前主Mon是Node-1
    &quot;quorum_age&quot;: 234,
    &quot;monmap&quot;: &#123;
        &quot;epoch&quot;: 3,
        &quot;fsid&quot;: &quot;e9a90625-4707-4b6b-b52f-661512ea831d&quot;,
        &quot;modified&quot;: &quot;2023-03-03 12:22:43.254681&quot;,
        &quot;created&quot;: &quot;2023-03-03 11:59:53.474948&quot;,
        &quot;min_mon_release&quot;: 14,
        &quot;min_mon_release_name&quot;: &quot;nautilus&quot;,
        &quot;features&quot;: &#123;
            &quot;persistent&quot;: [
                &quot;kraken&quot;,
                &quot;luminous&quot;,
                &quot;mimic&quot;,
                &quot;osdmap-prune&quot;,
                &quot;nautilus&quot;
            ],
            &quot;optional&quot;: []
        &#125;,
        &quot;mons&quot;: [
            &#123;
                &quot;rank&quot;: 0,
                &quot;name&quot;: &quot;node-1&quot;,
                &quot;public_addrs&quot;: &#123;
                    &quot;addrvec&quot;: [
                        &#123;
                            &quot;type&quot;: &quot;v2&quot;,
                            &quot;addr&quot;: &quot;192.168.187.201:3300&quot;,
                            &quot;nonce&quot;: 0
                        &#125;,
                        &#123;
                            &quot;type&quot;: &quot;v1&quot;,
                            &quot;addr&quot;: &quot;192.168.187.201:6789&quot;,
                            &quot;nonce&quot;: 0
                        &#125;
                    ]
                &#125;,
                &quot;addr&quot;: &quot;192.168.187.201:6789/0&quot;,
                &quot;public_addr&quot;: &quot;192.168.187.201:6789/0&quot;
            &#125;,
            &#123;
                &quot;rank&quot;: 1,
                &quot;name&quot;: &quot;node-2&quot;,
                &quot;public_addrs&quot;: &#123;
                    &quot;addrvec&quot;: [
                        &#123;
                            &quot;type&quot;: &quot;v2&quot;,
                            &quot;addr&quot;: &quot;192.168.187.202:3300&quot;,
                            &quot;nonce&quot;: 0
                        &#125;,
                        &#123;
                            &quot;type&quot;: &quot;v1&quot;,
                            &quot;addr&quot;: &quot;192.168.187.202:6789&quot;,
                            &quot;nonce&quot;: 0
                        &#125;
                    ]
                &#125;,
                &quot;addr&quot;: &quot;192.168.187.202:6789/0&quot;,
                &quot;public_addr&quot;: &quot;192.168.187.202:6789/0&quot;
            &#125;,
            &#123;
                &quot;rank&quot;: 2,
                &quot;name&quot;: &quot;node-3&quot;,
                &quot;public_addrs&quot;: &#123;
                    &quot;addrvec&quot;: [
                        &#123;
                            &quot;type&quot;: &quot;v2&quot;,
                            &quot;addr&quot;: &quot;192.168.187.203:3300&quot;,
                            &quot;nonce&quot;: 0
                        &#125;,
                        &#123;
                            &quot;type&quot;: &quot;v1&quot;,
                            &quot;addr&quot;: &quot;192.168.187.203:6789&quot;,
                            &quot;nonce&quot;: 0
                        &#125;
                    ]
                &#125;,
                &quot;addr&quot;: &quot;192.168.187.203:6789/0&quot;,
                &quot;public_addr&quot;: &quot;192.168.187.203:6789/0&quot;
            &#125;
        ]
    &#125;
&#125;
[root@node-1 my-cluster]#  ceph mon stat #查看Mon 状态
e3: 3 mons at &#123;node-1=[v2:192.168.187.201:3300/0,v1:192.168.187.201:6789/0],node-2=[v2:192.168.187.202:3300/0,v1:192.168.187.202:6789/0],node-3=[v2:192.168.187.203:3300/0,v1:192.168.187.203:6789/0]&#125;, election epoch 12, leader 0 node-1, quorum 0,1,2 node-1,node-2,node-3
[root@node-1 my-cluster]# ceph mon dump #查看Mon 状态
epoch 3
fsid e9a90625-4707-4b6b-b52f-661512ea831d
last_changed 2023-03-03 12:22:43.254681
created 2023-03-03 11:59:53.474948
min_mon_release 14 (nautilus)
0: [v2:192.168.187.201:3300/0,v1:192.168.187.201:6789/0] mon.node-1
1: [v2:192.168.187.202:3300/0,v1:192.168.187.202:6789/0] mon.node-2
2: [v2:192.168.187.203:3300/0,v1:192.168.187.203:6789/0] mon.node-3
dumped monmap epoch 3
</code></pre>
<h2><span id="二-mgr">二、MGR</span></h2><p><strong>MGR默认是主备模式</strong></p>
<p><strong>node-1：执行</strong></p>
<pre><code>[root@node-1 my-cluster]#  ceph-deploy mgr create node-2 node-3 #添加node-2 node-3 成为mgr
[root@node-1 my-cluster]#  ceph -s  #查看MGR状态
  cluster:
    id:     e9a90625-4707-4b6b-b52f-661512ea831d
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum node-1,node-2,node-3 (age 11m)
    mgr: node-1(active, since 28m), standbys: node-2, node-3 #可以看到备MGR为：node-2和node-3
    osd: 3 osds: 3 up (since 18m), 3 in (since 18m)
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   3.0 GiB used, 27 GiB / 30 GiB avail
    pgs:
[root@node-1 my-cluster]# ceph mgr dump #查看具体MAP图
</code></pre>
<h1><span id="十-创建资源池pool">十、创建资源池Pool</span></h1><pre><code>Node-1执行：
[root@node-1 my-cluster]# ceph osd lspools #查看当前pool
[root@node-1 my-cluster]# ceph osd pool create ceph-demo 64 64 #创建一个叫做ceph-demo的pool 并指定PG数为64（第一个数字），pgp数64（第二个数字）
pool &#39;ceph-demo&#39; created
[root@node-1 my-cluster]# ceph osd lspools #再次查看当前pool 新增了要给ceph-demo的pool
1 ceph-demo
[root@node-1 my-cluster]#  ceph osd pool get ceph-demo pg_num #查看ceph-demo的PG数量
pg_num: 64
[root@node-1 my-cluster]#  ceph osd pool get ceph-demo pgp_num #查看ceph-demo的PGP数量
pgp_num: 64
[root@node-1 my-cluster]#  ceph osd pool get ceph-demo size #查看ceph-demo的副本数
size: 3
[root@node-1 my-cluster]#  ceph osd pool get ceph-demo crush_rule #查看crush的调度算法
crush_rule: replicated_rule #默认的复制规则
[root@node-1 my-cluster]#   ceph osd pool set ceph-demo size 2  #可以通过set的方式调整副本数量为2
set pool 1 size to 2
[root@node-1 my-cluster]# ceph osd pool set ceph-demo pg_num 128 #可以通过set的方式调整pg数量为128
set pool 1 pg_num to 128
[root@node-1 my-cluster]# ceph osd pool set ceph-demo pgp_num 128 #可以通过set的方式调整pgp数量为128,PGP数量应该与PG数一致
set pool 1 pgp_num to 12
[root@node-1 my-cluster]# rbd pool init &lt;pool_name&gt; #初始化pool
</code></pre>
<script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">
      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/zhangboc/zhangboc.github.io.git/2023/04/11/Ceph/3.Ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/Ceph-%E5%AE%89%E8%A3%85/" data-id="clgd2kqbl000eso5fh1ts54rf" data-title="Ceph-安装" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ceph/" rel="tag">Ceph</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/04/11/Ceph/4.RBD%E5%9D%97%E5%AD%98%E5%82%A8/RBD%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">RBD写入流程</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Ceph/">Ceph</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ceph/" rel="tag">Ceph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ceph-FS/" rel="tag">Ceph FS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ceph%E7%AE%80%E4%BB%8B/" rel="tag">Ceph简介</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RBD/" rel="tag">RBD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RGW/" rel="tag">RGW</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chatjs/" rel="tag">chatjs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/" rel="tag">故障排查</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Ceph/" style="font-size: 20px;">Ceph</a> <a href="/tags/Ceph-FS/" style="font-size: 10px;">Ceph FS</a> <a href="/tags/Ceph%E7%AE%80%E4%BB%8B/" style="font-size: 10px;">Ceph简介</a> <a href="/tags/RBD/" style="font-size: 15px;">RBD</a> <a href="/tags/RGW/" style="font-size: 10px;">RGW</a> <a href="/tags/chatjs/" style="font-size: 10px;">chatjs</a> <a href="/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/" style="font-size: 10px;">故障排查</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/04/11/Ceph/3.Ceph%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/Ceph-%E5%AE%89%E8%A3%85/">Ceph-安装</a>
          </li>
        
          <li>
            <a href="/2023/04/11/Ceph/4.RBD%E5%9D%97%E5%AD%98%E5%82%A8/RBD%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/">RBD写入流程</a>
          </li>
        
          <li>
            <a href="/2023/04/11/Ceph/4.RBD%E5%9D%97%E5%AD%98%E5%82%A8/RBD%E5%9D%97%E5%88%9B%E5%BB%BA%E5%8F%8A%E6%98%A0%E5%B0%84/">RBD块创建及映射</a>
          </li>
        
          <li>
            <a href="/2023/04/11/Ceph/4.RBD%E5%9D%97%E5%AD%98%E5%82%A8/RBD%E5%9D%97%E5%AD%98%E5%82%A8%E6%89%A9%E5%AE%B9%E5%8F%8A%E7%BC%A9%E5%AE%B9/">RBD存储扩容/缩容</a>
          </li>
        
          <li>
            <a href="/2023/04/11/Ceph/5.RGW%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/RGW%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/">RGW对象存储</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script src="/live2D/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2D/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":true,"model":{"jsonPath":"/live2D/assets/xiaomai.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":1},"log":false});</script></body>
</html>